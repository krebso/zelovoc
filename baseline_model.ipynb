{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96e5f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "data_dir = \"dataset/\"\n",
    "\n",
    "def get_image_mean(image):\n",
    "    return np.mean(image, axis=(0, 1))\n",
    "\n",
    "\n",
    "def load_image_cropped(path):\n",
    "    im = load_img(path)\n",
    "    width, height = im.size\n",
    "\n",
    "    crop_size = 224\n",
    "    if width < crop_size or height < crop_size:\n",
    "        return im\n",
    "\n",
    "    left = (width - crop_size)/2\n",
    "    top = (height - crop_size)/2\n",
    "    right = (width + crop_size)/2\n",
    "    bottom = (height + crop_size)/2\n",
    "\n",
    "    # Crop the center of the image\n",
    "    im = im.crop((left, top, right, bottom))\n",
    "\n",
    "    return im\n",
    "\n",
    "\n",
    "def load_images(data_type, class_name):\n",
    "    path = os.path.join(data_dir, data_type, class_name)\n",
    "    images = os.listdir(path)\n",
    "        \n",
    "    if data_type == \"train\":\n",
    "        return np.mean(np.array([get_image_mean(img_to_array(load_image_cropped(os.path.join(path, image)))) for image in images]), axis=0)\n",
    "    \n",
    "    return [img_to_array(load_image_cropped(os.path.join(path, image))) for image in images]\n",
    "\n",
    "\n",
    "def create_data(data_type):\n",
    "    return {\n",
    "        class_name: load_images(data_type, class_name)\n",
    "        for class_name in os.listdir(os.path.join(data_dir, data_type))\n",
    "    }\n",
    "\n",
    "\n",
    "train_data = create_data(\"train\")\n",
    "test_data = create_data(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e734b2b3-8e71-420d-831a-1520a2f2e76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2200557103064067"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_image(image, train):\n",
    "    image_mean = get_image_mean(image)\n",
    "    minimal_distance = np.linalg.norm(np.array((0, 0, 0)) - np.array((255, 255, 255))) + 1\n",
    "    minimal_distance_class = \"\"\n",
    "    for class_name in train.keys():\n",
    "        distance = np.linalg.norm(image_mean - train[class_name])\n",
    "        if distance < minimal_distance:\n",
    "            minimal_distance = distance\n",
    "            minimal_distance_class = class_name\n",
    "    return minimal_distance_class\n",
    "\n",
    "\n",
    "def evaluate(train, test):\n",
    "    total_length = 0\n",
    "    correct_predictions = 0\n",
    "    for class_name, image_list in test.items():\n",
    "        total_length += len(image_list)\n",
    "        correct_predictions += sum([1 if predict_image(image, train) == class_name else 0 for image in image_list])\n",
    "    return correct_predictions / total_length\n",
    "\n",
    "\n",
    "evaluate(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ab697a-47bc-437a-89ad-7edf3d130610",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "Q: How does it work?\n",
    "A: For each image it creates a 3D vector that is a mean of the pixel colour value of the image.\n",
    "   For training it takes those vectors and creates a mean of them.\n",
    "   For predicting an image it calculates the euclidean distance between the mean of the image and vector of each class and predicts the closes class.\n",
    "\n",
    "Q: Why is it so bad and inefficient?\n",
    "A: Because I am both mentally and physically ill, so instead of browsing google for ages I created my own spaghetti code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25a90b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "\n",
    "def show_image(path):\n",
    "    im = load_img(path)\n",
    "    imshow(np.asarray(im))\n",
    "\n",
    "\n",
    "def show_image_cropped(path):\n",
    "    im = load_image_cropped(path)\n",
    "    imshow(np.asarray(im))\n",
    "\n",
    "    \n",
    "def show_mean_color(path):\n",
    "    mean = get_image_mean(load_img(path))\n",
    "    mean = mean.reshape(1,1,3) / 255\n",
    "    imshow(mean)\n",
    "\n",
    "\n",
    "path = \"dataset/train/apple/Image_1.jpg\"\n",
    "#show_image(path)\n",
    "\n",
    "#show_image_cropped(path)\n",
    "show_mean_color(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf1970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
