{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"V3DNY80MFBgu"},"outputs":[],"source":["%pip install --upgrade pip > /dev/null\n","%pip install matplotlib > /dev/null\n","%pip install PILLOW > /dev/null\n","%pip install numpy > /dev/null\n","%pip install pandas > /dev/null\n","%pip install torch > /dev/null\n","%pip install torchvision > /dev/null\n","%pip install tensorflow > /dev/null"],"id":"V3DNY80MFBgu"},{"cell_type":"code","execution_count":null,"metadata":{"id":"bYp70iQNFBg9"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","plt.rcParams[\"figure.figsize\"] = (20,5)\n","\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms, models\n","\n","import os\n","from copy import copy\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"id":"bYp70iQNFBg9"},{"cell_type":"code","execution_count":null,"metadata":{"id":"PfyyHAWuFBhA"},"outputs":[],"source":["zelovoc  = \"/content/drive/MyDrive/zelovoc/\"\n","train    = zelovoc + \"dataset/train\"\n","test     = zelovoc + \"dataset/test\"\n","validate = zelovoc + \"dataset/validate\""],"id":"PfyyHAWuFBhA"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZmOQIMqMFBhD"},"outputs":[],"source":["def get_image_filepaths( class_=\"apple\" ):\n","    return [ fn for fn in os.listdir(f'{ train }/{ class_ }') if fn.endswith( \".jpg\" ) ]"],"id":"ZmOQIMqMFBhD"},{"cell_type":"markdown","metadata":{"id":"91I_42NmFBhE"},"source":["# Exploratory data analysis\n","\n","Let's give our data a closer look, and determine how are individual fruits distributed "],"id":"91I_42NmFBhE"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Znl27bumFBhM"},"outputs":[],"source":["classes = { class_: len( os.listdir( f\"{ train }/{ class_ }\" ) ) for class_ in os.listdir(train) }\n","\n","plt.bar(classes.keys(), classes.values(), width = 0.7)\n","plt.title(\"Number of Images by Class\")\n","plt.xlabel('Class Name')\n","plt.xticks(rotation='vertical')\n","plt.ylabel('# Images');\n"],"id":"Znl27bumFBhM"},{"cell_type":"markdown","metadata":{"id":"5ZaF7dvyFBhR"},"source":["As we can see, the individual classes are pretty uniformly distributed, there is none that could cause bias in our data (hopefully)\n","\n","Function `disp_class` allows us to display `n` random samples of given class, so lets look at few apples"],"id":"5ZaF7dvyFBhR"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Egg6kJQOFBhU"},"outputs":[],"source":["from tensorflow.keras.preprocessing import image\n","\n","def disp_class( n_samples=10, class_=\"apple\" ):\n","    images = get_image_filepaths( class_ )\n","    \n","    n_samples = min( n_samples, len( images ) )\n","\n","    select = np.random.choice( images, n_samples, replace=False )\n","    fig = plt.figure( figsize=( 8, 6 ) )\n","\n","    for i in range( len( select ) ):\n","        fp = f'{ train }/{ class_ }/{ select[ i ] }'\n","        ax = fig.add_subplot( n_samples // 3 + 1 , 3, i+1 )\n","\n","        fn = image.load_img( fp, target_size=( 256, 256 ) )\n","        plt.imshow( fn )\n","        plt.title( class_ )\n","        plt.axis( 'off' )\n","\n","    plt.show()\n","    \n","disp_class( 10, \"apple\" )\n"],"id":"Egg6kJQOFBhU"},{"cell_type":"markdown","metadata":{"id":"B3lmuYjWFBhZ"},"source":["As can be seen, all apples in out training dataset are red, this might cause quite poor performance on real-world data, as apples are quite ofter green or yellow"],"id":"B3lmuYjWFBhZ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"wGHOLMREFBha"},"outputs":[],"source":["def img2np(path, list_of_filename, size = (64, 64)):\n","    for fn in list_of_filename:\n","        fp = path + fn\n","        # current_image = image.load_img(fp, target_size = size, color_mode = 'grayscale')\n","        current_image = image.load_img(fp, target_size = size, color_mode = 'grayscale')\n","\n","        img_ts = image.img_to_array(current_image)\n","\n","        img_ts = [img_ts.ravel()]\n","        try:\n","            full_mat = np.concatenate((full_mat, img_ts))\n","        except UnboundLocalError: \n","            full_mat = img_ts\n","    return full_mat\n","\n","def find_img_stat( matrix, class_, title, shape=( 64, 64 ), f=np.mean, **f_kwargs ):\n","    img = f( matrix, **f_kwargs )\n","    img = img.reshape( shape )\n","    plt.imshow( img, vmin=0, vmax=255,  )\n","    plt.title( title )\n","    plt.axis( \"off\" )\n","    plt.show()\n","    return img"],"id":"wGHOLMREFBha"},{"cell_type":"markdown","metadata":{"id":"P1F339ezFBhf"},"source":["Now lets look at more interesting statistics about our dataset, we created a function which turns an image into matrix and then compute desired result using some `numpy` function"],"id":"P1F339ezFBhf"},{"cell_type":"code","execution_count":null,"metadata":{"id":"QuXOIRU5FBhi"},"outputs":[],"source":["apple_images = img2np(f'{train}/apple/', get_image_filepaths( \"apple\" ) )\n","kiwi_images = img2np(f'{train}/kiwi/', get_image_filepaths( \"kiwi\" ) )\n","pineapple_images = img2np(f'{train}/pineapple/', get_image_filepaths( \"pineapple\" ) )\n","\n","apple_mean = find_img_stat( apple_images, \"apple\", \"apple mean\", f=np.mean, axis=0 )\n","kiwi_var = find_img_stat( kiwi_images, \"kiwi\", \"kiwi variance\", f=np.var, axis=0 )\n","pineapple_dev = find_img_stat( pineapple_images, \"pineapple\", \"pineapple deviation\", f=np.std, axis=0 )"],"id":"QuXOIRU5FBhi"},{"cell_type":"markdown","metadata":{"id":"mA7HPNlmFBhn"},"source":["Last but not least, we will use PCA to find componensts, which describe each class the best"],"id":"mA7HPNlmFBhn"},{"cell_type":"code","execution_count":null,"metadata":{"id":"S9PLj9ztFBhq"},"outputs":[],"source":["from sklearn.decomposition import PCA\n","from math import ceil\n","\n","def eigenimages( matrix, n_components = 0.3, size = (64, 64)):\n","    pca = PCA( n_components=n_components, whiten=True )\n","    pca.fit( matrix )\n","    return pca\n","  \n","def plot_pca( pca, title, size = (64, 64) ):\n","    n = pca.n_components_\n","    fig = plt.figure( figsize=( 8, 8 ) )\n","    \n","    r = int( n ** 0.5 )\n","    c = ceil( n / r)\n","    \n","    for i in range(n):\n","        ax = fig.add_subplot( r, c, i + 1, xticks=[], yticks=[] )\n","        ax.imshow( pca.components_[ i ].reshape( size ) )\n","        plt.title( f\"{ title }: { i + 1 }\" )\n","    plt.axis( \"off\" )\n","    plt.show()\n","    \n","plot_pca( eigenimages( apple_images ), \"apple\" )\n","plot_pca( eigenimages( kiwi_images ), \"kiwi\" )\n"],"id":"S9PLj9ztFBhq"},{"cell_type":"markdown","metadata":{"id":"1MZs8ZZlFBhv"},"source":["# Data Preparation"],"id":"1MZs8ZZlFBhv"},{"cell_type":"code","execution_count":null,"metadata":{"id":"vOEeyY0PFBhw"},"outputs":[],"source":["transforms = transforms.Compose([\n","    transforms.Resize( 256 ),\n","    transforms.CenterCrop( 224 ),\n","    transforms.ToTensor(),\n","    transforms.Normalize( mean=[ 0.485, 0.456, 0.406 ], std=[ 0.229, 0.224, 0.225 ] ),\n","])\n","\n","train_data = datasets.ImageFolder( train, transform=copy( transforms ) )\n","test_data = datasets.ImageFolder( test, transform=copy( transforms ) )\n","    \n","trainloader = torch.utils.data.DataLoader( train_data, batch_size=64 )\n","testloader = torch.utils.data.DataLoader( test_data, batch_size=64 )\n","\n","# trainloader.dataset.classes"],"id":"vOEeyY0PFBhw"},{"cell_type":"markdown","metadata":{"id":"JBNxQT3NFBiI"},"source":["# Model specification"],"id":"JBNxQT3NFBiI"},{"cell_type":"code","execution_count":null,"metadata":{"id":"xMUeghM-FBiL"},"outputs":[],"source":["# lets abuse GPU if possible\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = models.resnet18(pretrained=True)"],"id":"xMUeghM-FBiL"},{"cell_type":"code","execution_count":null,"metadata":{"id":"YpbxNPmpFBiN"},"outputs":[],"source":["# for param in model.parameters():\n","#     param.requires_grad = False\n","#     \n","# model.fc = nn.Sequential(nn.Linear(2048, 512),\n","#                                  nn.ReLU(),\n","#                                  nn.Dropout(0.2),\n","#                                  nn.Linear(512, 10),\n","#                                  nn.LogSoftmax(dim=1))\n","criterion = nn.NLLLoss()\n","optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n","model.to(device)\n","# model = torch.hub.load( \"pytorch/vision:v0.10.0\", \"resnet18\", pretrained=True )"],"id":"YpbxNPmpFBiN"},{"cell_type":"markdown","metadata":{"id":"KN2yhESdFBiO"},"source":["# Model Training"],"id":"KN2yhESdFBiO"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ny3EsZadFBiQ"},"outputs":[],"source":["epochs = 35\n","steps = 0\n","running_loss = 0\n","print_every = 10\n","train_losses, test_losses = [], []\n","\n","for epoch in range( epochs ):\n","    for inputs, labels in trainloader:\n","        steps += 1\n","        \n","        inputs, labels = inputs.to( device ), labels.to( device )\n","        \n","        optimizer.zero_grad()\n","        \n","        logps = model.forward( inputs )\n","        \n","        loss = criterion( logps, labels )\n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","        running_loss += loss.item()\n","        \n","        if steps % print_every == 0:\n","            test_loss = 0\n","            accuracy = 0\n","            model.eval()\n","            \n","            with torch.no_grad():\n","                for inputs, labels in testloader:\n","                    inputs, labels = inputs.to( device ), labels.to( device )\n","                    logps = model.forward( inputs )\n","                    \n","                    batch_loss = criterion( logps, labels )\n","                    test_loss += batch_loss.item()\n","                    \n","                    ps = torch.exp(logps)\n","                    top_p, top_class = ps.topk(1, dim=1)\n","                    equals = top_class == labels.view( *top_class.shape )\n","                    accuracy += torch.mean( equals.type( torch.FloatTensor) ).item()\n","            \n","            train_losses.append( running_loss / len(trainloader) )\n","            test_losses.append( test_loss / len(testloader) )                    \n","            \n","            print(f\"Epoch { epoch + 1 }/{ epochs }.. \"\n","                  f\"Train loss: { running_loss / print_every:.3f }.. \"\n","                  f\"Test loss: { test_loss / len( testloader ):.3f }.. \"\n","                  f\"Test accuracy: { accuracy / len( testloader ):.3f }\")\n","            \n","            running_loss = 0\n","            model.train()\n","\n","torch.save( model, \"model.pth\" )"],"id":"ny3EsZadFBiQ"},{"cell_type":"markdown","metadata":{"id":"R4VyCOmVFBiR"},"source":["# Model Evaluation"],"id":"R4VyCOmVFBiR"},{"cell_type":"code","execution_count":null,"metadata":{"id":"QOe0MdV8FBiS"},"outputs":[],"source":["# TBD"],"id":"QOe0MdV8FBiS"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"colab":{"name":"resnet.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}